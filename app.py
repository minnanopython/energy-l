import streamlit as st
import yfinance as yf
import pandas as pd
from datetime import timedelta, date
from io import BytesIO
import zipfile
import altair as alt
# --------------------------------------------------------------------------------------
# éŠ˜æŸ„ã¨ã‚»ã‚¯ã‚¿ãƒ¼ã®è¨­å®š (ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®å®šç¾©ã‚’ä½¿ç”¨)
# --------------------------------------------------------------------------------------
st.set_page_config(
    page_title="energy-l",
    page_icon=":chart_with_upwards_trend:",
    layout="wide",
)
DEFAULT_SECTOR = "ç·åˆå•†ç¤¾"
SECTORS_RAW = {
    "ç·åˆå•†ç¤¾": {
        '8058.T': 'ä¸‰è±å•†äº‹', '8031.T': 'ä¸‰äº•ç‰©ç”£', '8001.T': 'ä¼Šè—¤å¿ å•†äº‹',
        '8053.T': 'ä½å‹å•†äº‹', '8002.T': 'ä¸¸ç´…', '8015.T': 'è±Šç”°é€šå•†',
        '2768.T': 'åŒæ—¥', '8020.T': 'å…¼æ¾',
    },
    "ã‚¨ãƒãƒ«ã‚®ãƒ¼è³‡æº": {
        '5020.T': 'ï¼¥ï¼®ï¼¥ï¼¯ï¼³ï¼¨ï¼¤', '5019.T': 'å‡ºå…‰èˆˆç”£', '5021.T': 'ã‚³ã‚¹ãƒ¢ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼¨ï¼¤',
        '1605.T': 'ï¼©ï¼®ï¼°ï¼¥ï¼¸', '1662.T': 'çŸ³æ²¹è³‡æºé–‹ç™º', '1515.T': 'æ—¥é‰„é‰±æ¥­',
    },
    "ä¸»è¦é›»åŠ›": {
        '9509.T': 'åŒ—æµ·é“é›»åŠ›', '9506.T': 'æ±åŒ—é›»åŠ›', '9501.T': 'æ±äº¬é›»åŠ›ï¼¨ï¼¤',
        '9502.T': 'ä¸­éƒ¨é›»åŠ›', '9503.T': 'é–¢è¥¿é›»åŠ›', '9505.T': 'åŒ—é™¸é›»åŠ›',
        '9504.T': 'ä¸­å›½é›»åŠ›', '9507.T': 'å››å›½é›»åŠ›', '9508.T': 'ä¹å·é›»åŠ›',
        '9511.T': 'æ²–ç¸„é›»åŠ›', '9513.T': 'é›»æºé–‹ç™º',
    },
    "é›»åŠ›é›»è¨­": {
        '1934.T': 'ãƒ¦ã‚¢ãƒ†ãƒƒã‚¯', '1942.T': 'é–¢é›»å·¥', '1946.T': 'ãƒˆãƒ¼ã‚¨ãƒãƒƒã‚¯',
        '1944.T': 'ãã‚“ã§ã‚“', '1930.T': 'åŒ—é™¸é›»æ°—å·¥äº‹', '1941.T': 'ä¸­é›»å·¥',
        '1959.T': 'ä¹é›»å·¥', '1939.T': 'å››é›»å·¥',
    },
    "é›»è¨­å·¥äº‹": {
        '1417.T': 'ãƒŸãƒ©ã‚¤ãƒˆãƒ»ãƒ¯ãƒ³', '1721.T': 'ã‚³ãƒ ã‚·ã‚¹ï¼¨ï¼¤', '1951.T': 'ã‚¨ã‚¯ã‚·ã‚ªã‚°ãƒ«ãƒ¼ãƒ—',
        '1945.T': 'æ±äº¬ã‚¨ãƒã‚·ã‚¹', '1950.T': 'æ—¥æœ¬é›»è¨­å·¥æ¥­', '1938.T': 'æ—¥æœ¬ãƒªãƒ¼ãƒ†ãƒƒã‚¯',
    },
}
SECTORS = SECTORS_RAW
ALL_STOCKS_MAP = {ticker: name for sector in SECTORS_RAW.values() for ticker, name in sector.items()}
ALL_TICKERS_FLAT = list(ALL_STOCKS_MAP.keys())
ALL_TICKERS_WITH_N225 = list(set(ALL_TICKERS_FLAT + ['^N225']))

# éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚»ã‚¯ã‚¿ãƒ¼åã‚’å–å¾—ã™ã‚‹ãŸã‚ã®é€†å¼•ããƒãƒƒãƒ—ã‚’ä½œæˆ
TICKER_TO_SECTOR = {}
for sector_name, tickers in SECTORS_RAW.items():
    for ticker in tickers.keys():
        TICKER_TO_SECTOR[ticker] = sector_name

# --------------------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¡Œã†é–¢æ•° (çµ±åˆç‰ˆ)
# --------------------------------------------------------------------------------------
@st.cache_data(show_spinner=True, ttl=timedelta(minutes=30))
def load_ohlcv_data(tickers_list):
    """
    OHLCVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹é–¢æ•°ã€‚
    Wideå½¢å¼ (MultiIndex) ã¨ Longå½¢å¼ã®DataFrameã‚’è¿”ã™ã€‚
    """
    unique_tickers = list(set(tickers_list))
    if not unique_tickers:
        return pd.DataFrame(), pd.DataFrame() 
    try:
        tickers_obj = yf.Tickers(unique_tickers)
        data_wide = tickers_obj.history(period="max", interval="1d", auto_adjust=True)
    except Exception as e:
        st.error(f"yfinanceãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame(), pd.DataFrame() 
    if data_wide.empty:
        return pd.DataFrame(), pd.DataFrame()
    if len(unique_tickers) == 1 and not isinstance(data_wide.columns, pd.MultiIndex):
        data_wide.columns = pd.MultiIndex.from_product([data_wide.columns, unique_tickers], names=['Variable', 'Ticker'])
    data_wide = data_wide.dropna(axis=0, how='all')
    data_long = data_wide.stack(level='Ticker', future_stack=True).rename_axis(['Date', 'Ticker']).reset_index()
    data_long = data_long.rename(columns={'Close': 'Close_Today', 'Open': 'Open_Today', 'High': 'High_Today', 'Low': 'Low_Today', 'Volume': 'Volume_Today'})
    data_long['Close_Yesterday'] = data_long.groupby('Ticker')['Close_Today'].shift(1)
    return data_wide, data_long

# --------------------------------------------------------------------------------------
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ç”¨è£œåŠ©é–¢æ•°
# --------------------------------------------------------------------------------------
def is_multiindex(df):
    """DataFrameãŒMultiIndexã‚’æŒã¤ã‹ãƒã‚§ãƒƒã‚¯"""
    return isinstance(df.columns, pd.MultiIndex)

# A1è¡¨è¨˜ã®åˆ—åã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (pandas 0.23ä»¥é™ã®xlwt.col_strã®ä»£ã‚ã‚Š)
def get_column_letter(col_idx):
    """0-indexed column index to A1 notation column letter (e.g., 0 -> A, 26 -> AA)"""
    col_idx += 1  # 1-indexedã«ã™ã‚‹
    letter = ''
    while col_idx > 0:
        col_idx, remainder = divmod(col_idx - 1, 26)
        letter = chr(65 + remainder) + letter
    return letter

def calculate_returns_with_dates(df, ticker, name_map, åŸºæº–æ—¥):
    """
    ç‰¹å®šã®éŠ˜æŸ„ã«ã¤ã„ã¦ã€åŸºæº–æ—¥ã‚’åŸºæº–ã¨ã—ãŸçŸ­æœŸï¼ˆéå»6å–¶æ¥­æ—¥ï¼‰ã¨é•·æœŸã®é¨°è½ç‡ã‚’è¨ˆç®—ã—ã€
    æŒ‡å®šã•ã‚ŒãŸæ—¥æ¬¡ã®å®‰å€¤ã€é«˜å€¤ã€çµ‚å€¤ã€RGã€ãƒœãƒ©ï¼ˆä¾¡æ ¼ã®å·®ï¼‰ã‚’è¿½åŠ ã™ã‚‹ã€‚
    """
    if is_multiindex(df):
        if ticker not in df.columns.levels[1]:
            return pd.DataFrame()
        ohlc = df.loc[:, (slice(None), ticker)]
        ohlc.columns = ohlc.columns.get_level_values(0)
    else:
        # 1éŠ˜æŸ„ã ã‘ã®å ´åˆ
        ohlc = df
        ohlc.columns = ohlc.columns.get_level_values(0)

    ohlc = ohlc.dropna()
    if ohlc.empty or "Close" not in ohlc.columns:
        return pd.DataFrame()
    available_dates = ohlc.index[ohlc.index <= åŸºæº–æ—¥]
    if len(available_dates) == 0:
        return pd.DataFrame()

    base_date = available_dates.max()
    base_idx = ohlc.index.get_loc(base_date)
    
    # éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆæœŸåŒ–
    result = pd.DataFrame()
    # ã‚»ã‚¯ã‚¿ãƒ¼åˆ—ã‚’è¿½åŠ  (æ—¥çµŒå¹³å‡ã®å ´åˆã¯ç©ºæ¬„/ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹/ãã®ä»–ã‚’è¨­å®š)
    sector_name = TICKER_TO_SECTOR.get(ticker, "")
    result["ã‚»ã‚¯ã‚¿ãƒ¼"] = [sector_name] if ticker != '^N225' else ["ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"]
    result["éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰"] = [ticker]
    result["éŠ˜æŸ„å"] = [name_map.get(ticker, "æ—¥çµŒå¹³å‡" if ticker == '^N225' else ticker)]
    result["æ ªä¾¡"] = [ohlc["Close"].iloc[base_idx]]
    
    # çŸ­æœŸï¼ˆéå»6å–¶æ¥­æ—¥ï¼‰ã®é¨°è½ç‡ã¨RG/ãƒœãƒ©ã‚’è¨ˆç®—
    for i in range(0, 6): 
        target_idx = base_idx - i
        prior_idx = base_idx - (i + 1)

        if prior_idx >= 0 and target_idx >= 0:
            date_str = ohlc.index[target_idx].strftime("%Y-%m-%d")
            prior_close = ohlc["Close"].iloc[prior_idx] 
            
            # å®‰å€¤/é«˜å€¤/çµ‚å€¤ (é¨°è½ç‡ %)
            result[f"{date_str}_å®‰å€¤"] = ((ohlc["Low"].iloc[target_idx] - prior_close) / prior_close * 100).round(2)
            result[f"{date_str}_é«˜å€¤"] = ((ohlc["High"].iloc[target_idx] - prior_close) / prior_close * 100).round(2)
            result[f"{date_str}_çµ‚å€¤"] = ((ohlc["Close"].iloc[target_idx] - prior_close) / prior_close * 100).round(2)
            
            # RG (å€¤å¹…ã®é¨°è½ç‡ %)
            result[f"{date_str}_ï¼²ï¼§"] = ((ohlc["High"].iloc[target_idx] - ohlc["Low"].iloc[target_idx]) / prior_close * 100).round(2)
            
            # ãƒœãƒ© (å€¤å¹…ã®é‡‘é¡)
            result[f"{date_str}_ãƒœãƒ©"] = (ohlc["High"].iloc[target_idx] - ohlc["Low"].iloc[target_idx]).round(2) 
        else:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯None
            date_str = ohlc.index[target_idx].strftime("%Y-%m-%d") if target_idx >= 0 and target_idx < len(ohlc.index) else f"D-{i+1}" 
            result[f"{date_str}_å®‰å€¤"] = None
            result[f"{date_str}_é«˜å€¤"] = None
            result[f"{date_str}_çµ‚å€¤"] = None
            result[f"{date_str}_ï¼²ï¼§"] = None
            result[f"{date_str}_ãƒœãƒ©"] = None
            
    # é•·æœŸã®é¨°è½ç‡ã‚’è¨ˆç®—
    periods = {
        "5d": 5,
        "10d": 10,
        "1mo": 21,
        "2mo": 42,
        "3mo": 63,
        "4mo": 84,
        "5mo": 105,
        "6mo": 126,
        "1y": 252,
        "2y": 504,
    }
    for label, days in periods.items():
        prior_idx = base_idx - days
        if prior_idx >= 0:
            prior_close = ohlc["Close"].iloc[prior_idx]
            base_close = ohlc["Close"].iloc[base_idx]
            result[label] = ((base_close - prior_close) / prior_close * 100).round(2)
        else:
            result[label] = None
            
    return result

# --------------------------------------------------------------------------------------
# ã‚°ãƒ©ãƒ•æ©Ÿèƒ½ç”¨è£œåŠ©é–¢æ•° 
# --------------------------------------------------------------------------------------
def get_stock_name(ticker_code):
    """ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚³ãƒ¼ãƒ‰ã‹ã‚‰éŠ˜æŸ„åã‚’å–å¾—"""
    if ticker_code == '^N225':
        return "æ—¥çµŒå¹³å‡"
    return ALL_STOCKS_MAP.get(ticker_code, ticker_code)

def reset_stock_selection():
    """ã‚»ã‚¯ã‚¿ãƒ¼å¤‰æ›´æ™‚ã«éŠ˜æŸ„é¸æŠã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    st.session_state["_stock_selection_needs_reset"] = True

def calculate_returns_and_range(df_ohlcv_long: pd.DataFrame, filtered_tickers: list) -> dict:
    """
    æ—¥æ¬¡ã®çµ‚å€¤ã€å®‰å€¤ã€é«˜å€¤ã€ãƒ¬ãƒ³ã‚¸ã®é¨°è½ç‡ã‚’è¨ˆç®—ã—ã€ã‚°ãƒ©ãƒ•ç”¨ã®Longå½¢å¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™ã€‚
    """
    if df_ohlcv_long.empty or not filtered_tickers:
        return {}
    df = df_ohlcv_long[df_ohlcv_long['Ticker'].isin(filtered_tickers)].dropna(subset=['Close_Yesterday']).copy()
    df['Close_vs_Close'] = ((df['Close_Today'] - df['Close_Yesterday']) / df['Close_Yesterday']) * 100
    df['Close_vs_Low'] = ((df['Low_Today'] - df['Close_Yesterday']) / df['Close_Yesterday']) * 100
    df['Close_vs_High'] = ((df['High_Today'] - df['Close_Yesterday']) / df['Close_Yesterday']) * 100
    df['Daily_Range_Percent'] = ((df['High_Today'] - df['Low_Today']) / df['Close_Yesterday']) * 100
    df['Color_Close'] = df['Close_vs_Close'].apply(lambda x: 'Positive' if x >= 0 else 'Negative')
    df['Color_Low'] = df['Close_vs_Low'].apply(lambda x: 'Positive' if x >= 0 else 'Negative')
    df['Color_High'] = df['Close_vs_High'].apply(lambda x: 'Positive' if x >= 0 else 'Negative')
    df['Stock_Gained'] = df.groupby('Ticker')['Close_Today'].transform(lambda x: x.diff().gt(0))
    df['Color_Range'] = df['Stock_Gained'].apply(lambda x: 'Positive' if x else 'Negative')
    data_close = df[['Date', 'Ticker', 'Close_vs_Close', 'Color_Close']].rename(columns={'Close_vs_Close': 'Value', 'Color_Close': 'Color'})
    data_low = df[['Date', 'Ticker', 'Close_vs_Low', 'Color_Low']].rename(columns={'Close_vs_Low': 'Value', 'Color_Low': 'Color'})
    data_high = df[['Date', 'Ticker', 'Close_vs_High', 'Color_High']].rename(columns={'Close_vs_High': 'Value', 'Color_High': 'Color'})
    data_range = df[['Date', 'Ticker', 'Daily_Range_Percent', 'Color_Range']].rename(columns={'Daily_Range_Percent': 'Value', 'Color_Range': 'Color'})
    max_rows = 750 * len(filtered_tickers)
    data_close = data_close.tail(max_rows)
    data_low = data_low.tail(max_rows)
    data_high = data_high.tail(max_rows)
    data_range = data_range.tail(max_rows) 
    return {
        "çµ‚å€¤": data_close,
        "å®‰å€¤": data_low,
        "é«˜å€¤": data_high,
        "ãƒ¬ãƒ³ã‚¸": data_range
    }

def create_and_display_bar_charts(plot_df_all: pd.DataFrame, filtered_stocks: dict, tab_name: str, y_domain_gain=None):
    """
    å„æŒ‡æ¨™ã®æ£’ã‚°ãƒ©ãƒ•ã‚’Altairã§æç”»ã™ã‚‹ã€‚
    """
    if plot_df_all.empty:
        st.info(f"{tab_name}ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return 
    current_plot_tickers = [t for t in filtered_stocks.keys() if t in plot_df_all['Ticker'].unique()] 
    if not current_plot_tickers:
        st.info(f"{tab_name}ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return 
    num_cols = 1 
    if tab_name != "ãƒ¬ãƒ³ã‚¸" and y_domain_gain is not None:
        y_domain = y_domain_gain
    else:
        y_domain = 'unaggregated' 
    y_title = None
    y_format = "+.1f"
    color_range = ['#008000', '#C70025'] 
    plot_df_all['Date'] = plot_df_all['Date'].dt.date
    for ticker in current_plot_tickers:
        stock_name = get_stock_name(ticker) 
        plot_df = plot_df_all[plot_df_all['Ticker'] == ticker].copy() 
        x_format = "%Y/%m" 
        chart = alt.Chart(plot_df).mark_bar().encode(
            alt.X("Date:T", axis=alt.Axis(
                title=None,
                format=x_format,
                labelAngle=0,
                tickCount= 'month' 
            )),
            alt.Y("Value:Q", axis=alt.Axis(title=None, format=y_format),
                scale=alt.Scale(domain=y_domain)
            ),
            alt.Color('Color:N',
                scale=alt.Scale(domain=['Positive', 'Negative'], range=color_range),
                legend=None),
            tooltip=[
                alt.Tooltip("Date:T", title="æ—¥ä»˜", format="%Y/%m/%d"),
                alt.Tooltip("Value:Q", title="é¨°è½ç‡", format="+.2f"),
                alt.Tooltip("Color:N", title="å‚¾å‘")
            ]
        ).properties(
            title=f"{ticker[:4]} {stock_name}",
            height=300, 
        ) 
        # ğŸ’¡ ä¿®æ­£: use_container_width=True ã‚’ width='stretch' ã«å¤‰æ›´
        st.altair_chart(chart, width='stretch')
# --------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å®Ÿè¡Œ (Wide/Longå½¢å¼ã®ä¸¡æ–¹ã‚’ä¸€åº¦ã«å–å¾—)
# --------------------------------------------------------------------------------------
ohlcv_data_wide, ohlcv_data_long = pd.DataFrame(), pd.DataFrame()
try:
    with st.spinner(f"å…¨éŠ˜æŸ„ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­ (æœ€å¤§æœŸé–“)..."):
        # æ—¥çµŒå¹³å‡ã¯é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã«ã¯å«ã‚ãªã„ãŒã€ã‚°ãƒ©ãƒ•ã®ãŸã‚ã«å–å¾—å¯¾è±¡ã«å«ã‚ã‚‹
        download_tickers_plus_n225 = ALL_TICKERS_FLAT + ['^N225']
        ohlcv_data_wide, ohlcv_data_long = load_ohlcv_data(download_tickers_plus_n225) 
except Exception as e:
    if "YFRateLimitError" in str(e):
        st.warning("YFinanceã®æ¥ç¶šåˆ¶é™ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        load_ohlcv_data.clear()
    else:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop() 
if ohlcv_data_wide.empty or ohlcv_data_long.empty:
    st.error("OHLCVãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
    st.stop()

# --------------------------------------------------------------------------------------
# ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®é…ç½® (åŸºæº–æ—¥ã€ã‚»ã‚¯ã‚¿ãƒ¼ã€éŠ˜æŸ„)
# --------------------------------------------------------------------------------------
st.markdown("## âš™ï¸ Download")
""
col_download, col_select_sector, col_select_stock = st.columns([1, 1.5, 6])
with col_download:
    latest_date = ohlcv_data_wide.index.max().date() if not ohlcv_data_wide.empty else pd.Timestamp.today().date()
    # åŸºæº–æ—¥ï¼ˆãƒ©ãƒ™ãƒ«ã¯éè¡¨ç¤ºã ãŒã€è­¦å‘Šå›é¿ã®ãŸã‚è¨­å®šï¼‰
    åŸºæº–æ—¥ = st.date_input("åŸºæº–æ—¥_æ—¥ä»˜", latest_date, label_visibility="collapsed")
    åŸºæº–æ—¥ = pd.Timestamp(åŸºæº–æ—¥)
with col_select_sector:
    sector_options = list(SECTORS.keys())
    default_sector_key = DEFAULT_SECTOR
    default_sectors = st.session_state.get("multiselect_sectors", [default_sector_key])
    selected_sectors = st.multiselect(
        "ã‚»ã‚¯ã‚¿ãƒ¼ã‚’é¸æŠ",
        options=sector_options,
        default=default_sectors,
        key="multiselect_sectors",
        label_visibility="collapsed",
        on_change=reset_stock_selection
    ) 
SELECTED_SECTOR_STOCKS_MAP = {}
if selected_sectors:
    for sector in selected_sectors:
        SELECTED_SECTOR_STOCKS_MAP.update(SECTORS.get(sector, {}))
else:
    SELECTED_SECTOR_STOCKS_MAP = ALL_STOCKS_MAP 

stock_options = [name for name in SELECTED_SECTOR_STOCKS_MAP.values()]
all_current_stock_names = stock_options
if "æ—¥çµŒå¹³å‡" not in all_current_stock_names:
    all_current_stock_names.append("æ—¥çµŒå¹³å‡")
if "multiselect_stocks" not in st.session_state:
    st.session_state["multiselect_stocks"] = all_current_stock_names
elif st.session_state.get("_stock_selection_needs_reset"):
    st.session_state["multiselect_stocks"] = all_current_stock_names
    del st.session_state["_stock_selection_needs_reset"]
else:
    current_selection = st.session_state["multiselect_stocks"]
    st.session_state["multiselect_stocks"] = [name for name in current_selection if name in all_current_stock_names]

with col_select_stock:
    selected_stock_names = st.multiselect(
        "éŠ˜æŸ„ã‚’é¸æŠ",
        options=all_current_stock_names,
        key="multiselect_stocks",
        label_visibility="collapsed"
    ) 
FINAL_STOCKS_MAP = {}
name_to_ticker = {name: ticker for ticker, name in ALL_STOCKS_MAP.items()}
name_to_ticker["æ—¥çµŒå¹³å‡"] = '^N225'
for name in selected_stock_names:
    ticker = name_to_ticker.get(name)
    if ticker:
        FINAL_STOCKS_MAP[ticker] = name

FILTERED_STOCKS = FINAL_STOCKS_MAP
FILTERED_TICKERS = list(FINAL_STOCKS_MAP.keys())

# --- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç† ---
with col_download:
    # ğŸ’¡ ä¿®æ­£: use_container_width=True ã‚’ width='stretch' ã«å¤‰æ›´
    if st.button("ğŸ“¥ Download", width='stretch'): 
        all_results = []
        progress_bar = st.progress(0)
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ã¯è¨­å®šã•ã‚Œã¦ã„ã‚‹å…¨éŠ˜æŸ„ (æ—¥çµŒå¹³å‡å«ã‚€)
        download_tickers = ALL_TICKERS_FLAT + (['^N225'] if '^N225' in ALL_TICKERS_WITH_N225 else [])
        
        if not download_tickers:
            st.error("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ã®éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            with st.spinner(f"å…¨ {len(download_tickers)} éŠ˜æŸ„ã®é¨°è½ç‡è¨ˆç®—ä¸­..."):
                ohlcv_data_filtered = ohlcv_data_wide[ohlcv_data_wide.index <= åŸºæº–æ—¥]
                
                for i, ticker in enumerate(download_tickers):
                    res = calculate_returns_with_dates(ohlcv_data_filtered, ticker, ALL_STOCKS_MAP, åŸºæº–æ—¥)
                    if not res.empty:
                        all_results.append(res)
                    progress = (i + 1) / len(download_tickers)
                    progress_bar.progress(progress) 
                
                progress_bar.empty() 
                
                if len(all_results) == 0:
                    st.error("é¨°è½ç‡ã®è¨ˆç®—ã«æˆåŠŸã—ãŸéŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åŸºæº–æ—¥ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                else:
                    final_df = pd.concat(all_results, ignore_index=True)
                    
                    # æ—¥çµŒå¹³å‡ (^N225) ã®è¡Œã‚’å…ˆé ­ã«ç§»å‹•ã•ã›ã‚‹
                    n225_df = final_df[final_df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] == '^N225']
                    other_stocks_df = final_df[final_df['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'] != '^N225']
                    other_stocks_df = other_stocks_df.sort_values("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰").reset_index(drop=True)
                    final_df = pd.concat([n225_df, other_stocks_df], ignore_index=True)
                    
                    # --- Excelãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²ã®ãŸã‚ã®åˆ—åå®šç¾© ---
                    BASE_COLS = ["ã‚»ã‚¯ã‚¿ãƒ¼", "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰", "éŠ˜æŸ„å", "æ ªä¾¡"]
                    DAILY_RETURNS_COLS = [col for col in final_df.columns if '_å®‰å€¤' in col or '_é«˜å€¤' in col or '_çµ‚å€¤' in col]
                    LONG_TERM_RETURNS_COLS = [col for col in final_df.columns if col in ["5d", "10d", "1mo", "2mo", "3mo", "4mo", "5mo", "6mo", "1y", "2y"]]
                    TABLE1_COLS = BASE_COLS + DAILY_RETURNS_COLS + LONG_TERM_RETURNS_COLS
                    RG_VORA_COLS = [col for col in final_df.columns if '_ï¼²ï¼§' in col or '_ãƒœãƒ©' in col]
                    TABLE2_COLS = BASE_COLS + RG_VORA_COLS
                    CONDITIONAL_FORMAT_COLS = DAILY_RETURNS_COLS + LONG_TERM_RETURNS_COLS
                    
                    if CONDITIONAL_FORMAT_COLS:
                        first_data_col_idx = TABLE1_COLS.index(CONDITIONAL_FORMAT_COLS[0])
                        last_data_col_idx = TABLE1_COLS.index(CONDITIONAL_FORMAT_COLS[-1])
                        first_col_letter = get_column_letter(first_data_col_idx)
                        last_col_letter = get_column_letter(last_data_col_idx)
                    else:
                        first_data_col_idx = -1
                        last_data_col_idx = -1
                        
                    
                    split_size = 1000
                    excel_buffers = []
                    
                    for i in range(0, len(final_df), split_size):
                        chunk = final_df.iloc[i:i+split_size]
                        table1_df = chunk[TABLE1_COLS]
                        table2_df = chunk[TABLE2_COLS]
                        buffer = BytesIO()
                        
                        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                            table1_df.to_excel(writer, sheet_name='Daily_Returns_LongTerm', index=False)
                            table2_df.to_excel(writer, sheet_name='Daily_Range_Vola', index=False)
                            
                            workbook = writer.book
                            worksheet = writer.sheets['Daily_Returns_LongTerm']

                            if first_data_col_idx != -1 and last_data_col_idx != -1:
                                format_positive = workbook.add_format({'font_color': '#008000', 'num_format': '0.0'}) # ç·‘
                                format_negative = workbook.add_format({'font_color': '#C70025', 'num_format': '0.0'}) # èµ¤
                                format_neutral = workbook.add_format({'num_format': '0.0'}) # ã‚¼ãƒ­ãƒ»æœªå®šç¾©ç”¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)

                                conditional_range = f"{first_col_letter}2:{last_col_letter}{len(chunk) + 1}"

                                worksheet.set_column(first_data_col_idx, last_data_col_idx, None, format_neutral)
                                
                                worksheet.conditional_format(
                                    conditional_range,
                                    {'type': 'cell', 'criteria': '>', 'value': 0, 'format': format_positive}
                                )

                                worksheet.conditional_format(
                                    conditional_range,
                                    {'type': 'cell', 'criteria': '<', 'value': 0, 'format': format_negative}
                                )

                        buffer.seek(0)
                        excel_buffers.append((f"daily_returns_part_{i//split_size + 1}.xlsx", buffer))
                    
                    zip_buffer = BytesIO()
                    with zipfile.ZipFile(zip_buffer, "w") as zf:
                        for file_name, buffer in excel_buffers:
                            zf.writestr(file_name, buffer.getvalue())
                    zip_buffer.seek(0)
                    st.download_button(
                        label=f"âœ… ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (å…¨{len(final_df)}éŠ˜æŸ„)",
                        data=zip_buffer,
                        file_name=f"daily_returns_at_{åŸºæº–æ—¥.strftime('%Y%m%d')}.zip",
                        mime="application/zip",
                        # ğŸ’¡ ä¿®æ­£: use_container_width=True ã‚’ width='stretch' ã«å¤‰æ›´
                        width='stretch',
                    )

# --------------------------------------------------------------------------------------
# ã‚°ãƒ©ãƒ•æ©Ÿèƒ½ã®å®Ÿè¡Œ 
# --------------------------------------------------------------------------------------
""
st.markdown("## ğŸ“Š Chart")
""
final_y_min_gain = -20.0
final_y_max_gain = 20.0
if FILTERED_STOCKS:
    chart_data = calculate_returns_and_range(ohlcv_data_long, FILTERED_TICKERS)
    tab_close, tab_low, tab_high, tab_range = st.tabs(["çµ‚å€¤", "å®‰å€¤", "é«˜å€¤", "ãƒ¬ãƒ³ã‚¸"])
    with tab_close:
        if "çµ‚å€¤" in chart_data and not chart_data["çµ‚å€¤"].empty:
            create_and_display_bar_charts(
                chart_data["çµ‚å€¤"],
                FILTERED_STOCKS,
                "çµ‚å€¤",
                [final_y_min_gain, final_y_max_gain]
            )
        else:
            st.info("çµ‚å€¤ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
    with tab_low:
        if "å®‰å€¤" in chart_data and not chart_data["å®‰å€¤"].empty:
            create_and_display_bar_charts(
                chart_data["å®‰å€¤"],
                FILTERED_STOCKS,
                "å®‰å€¤",
                [final_y_min_gain, final_y_max_gain]
            )
        else:
            st.info("å®‰å€¤ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
    with tab_high:
        if "é«˜å€¤" in chart_data and not chart_data["é«˜å€¤"].empty:
            create_and_display_bar_charts(
                chart_data["é«˜å€¤"],
                FILTERED_STOCKS,
                "é«˜å€¤",
                [final_y_min_gain, final_y_max_gain]
            )
        else:
            st.info("é«˜å€¤ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
    with tab_range:
        if "ãƒ¬ãƒ³ã‚¸" in chart_data and not chart_data["ãƒ¬ãƒ³ã‚¸"].empty:
            create_and_display_bar_charts(
                chart_data["ãƒ¬ãƒ³ã‚¸"],
                FILTERED_STOCKS,
                "ãƒ¬ãƒ³ã‚¸",
            )
        else:
            st.info("ãƒ¬ãƒ³ã‚¸ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
else:
    st.info("ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹éŠ˜æŸ„ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚»ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")